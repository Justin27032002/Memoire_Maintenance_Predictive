{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48c4e695-4af7-46de-8baa-44beb296b415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script de traitement de scénarios de défauts simulés pour la maintenance prédictive.\n",
    "\n",
    "Ce script parcourt différents sous-dossiers contenant des fichiers CSV issus de simulations\n",
    "de défauts sur des microturbines. Pour chaque fichier :\n",
    "- Il identifie le début du défaut à partir du nom du fichier (via des expressions régulières).\n",
    "- Il tronque les données à partir de ce point pour ne garder que la phase de dégradation.\n",
    "- Il calcule la Remaining Useful Life (RUL) comme la différence entre le temps final\n",
    "  et chaque timestamp.\n",
    "- Il ne conserve que les colonnes de capteurs communes à tous les fichiers.\n",
    "- Il ajoute un identifiant d’unité (`unit_id`) basé sur le nom du fichier.\n",
    "\n",
    "Tous les fichiers valides sont fusionnés en un unique DataFrame et exportés en CSV,\n",
    "prêt à être utilisé pour des tâches de Machine Learning en régression de RUL.\n",
    "\n",
    "Destination finale :\n",
    "    /Volumes/dbe_dbx_internships/justin/predictive_maintenance/all_scenarios_with_RUL.csv\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54e47020-b26e-422f-83d1-3bd7c679cca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "base_folder = \"/Volumes/dbe_dbx_internships/justin/predictive_maintenance/\" # Dossier qui reprend tout les dossiers de chaque défaut\n",
    "output_file = os.path.join(base_folder, \"all_scenarios_with_RUL.csv\") \n",
    "\n",
    "subfolders = [ # Sous-dossiers contenus dans le base_folder\n",
    "    \"Defaut_CC_T\",\n",
    "    \"Defaut_Compresseur\",\n",
    "    \"Defaut_Fuite_Fuel\",\n",
    "    \"Defaut_Noise_TOT\",\n",
    "    \"Defaut_Rec_T\",\n",
    "    \"Defaut_Recuperateur\",\n",
    "    \"Defaut_Turbine\",\n",
    "    \"FiltreAir\",\n",
    "    \"Defaut_Mix_Final\",\n",
    "    \"Defaut_Tuyaux_cc_t\",\n",
    "    \"Defaut_Tuyaux_comp_rec\",\n",
    "    \"Defaut_Tuyaux_rec_cc\",\n",
    "    \"Defaut_Tuyaux_turb_rec\" \n",
    "]\n",
    "\n",
    "common_cols = [ # Colonnes communes à l'ensemble des dossiers de défauts\n",
    "    \"Time\",\"Nref\",\"N\",\"Power_Shaft\",\"Eff_Cycle\",\"Power_Comp\",\"Power_Turb\",\"Beta_Comp\",\"Beta_Turb\",\n",
    "    \"Is_Eff_Comp\",\"Is_Eff_Turb\",\"T_amb\",\"T_c_in\",\"T_c_out\",\"T_rec_c_in\",\"T_rec_c_out\",\"T_cc_in\",\n",
    "    \"T_cc_out\",\"T_t_in\",\"T_t_out\",\"T_rec_h_in\",\"T_rec_h_out\",\"p_amb\",\"p_c_in\",\"p_c_out\",\n",
    "    \"p_rec_c_in\",\"p_rec_c_out\",\"p_cc_in\",\"p_cc_out\",\"p_t_in\",\"p_t_out\",\"p_rec_h_in\",\"p_rec_h_out\",\n",
    "    \"m_amb\",\"m_c_in\",\"m_c_out\",\"m_rec_c_in\",\"m_rec_c_out\",\"m_cc_in\",\"m_cc_out\",\n",
    "    \"m_t_in\",\"m_t_out\",\"m_rec_h_in\",\"m_rec_h_out\",\"m_fuel\"\n",
    "]\n",
    "\n",
    "fault_mapping = { # Mapping pour la lecture des fichiers de défauts -> booléen : début du défaut\n",
    "    \"NoiseTOT\": \"StartTOT\",\n",
    "    \"NoiseFuel\": \"StartFuel\",\n",
    "    \"bool_eta_comp_deg\": \"start_comp_eff\",\n",
    "    \"bool_eta_turb\": \"start\",\n",
    "    \"bool_foul_CC_turb\": \"start_foul_CC_turb\",\n",
    "    \"bool_foul_recup_turb\": \"start_foul_T_REC\"\n",
    "}\n",
    "\n",
    "def extract_active_start(file_path):\n",
    "    \"\"\"\n",
    "    Extrait le moment de début du premier défaut actif à partir du chemin du fichier.\n",
    "\n",
    "    Cette version utilise le nom de dossier parent pour détecter le dossier 'Defaut_Mix' et\n",
    "    applique toujours le pattern SXXX_timestamp sur le basename.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    folder = os.path.basename(os.path.dirname(file_path))\n",
    "    \n",
    "    matches = re.findall(r\"(S[A-Z0-9]+)_(\\d+)\", filename) # Trouver tous les tags S..._(num) qui indique début du défaut\n",
    "    starts = [int(val) for tag, val in matches if int(val) != 0]\n",
    "\n",
    "    if 'Defaut_Mix' in folder: # Cas défaut mix\n",
    "        return min(starts) if starts else None\n",
    "\n",
    "    for foul_pattern in ['SF', 'SFR']: # Cas Recuperateur et Filtre à air\n",
    "        foul_match = re.search(f\"{foul_pattern}_?(\\d+)\", filename)\n",
    "        if foul_match and int(foul_match.group(1)) != 0:\n",
    "            starts.append(int(foul_match.group(1)))\n",
    "\n",
    "    for bool_key, start_key in fault_mapping.items():# Autres cas \n",
    "        if re.search(f\"{bool_key}_(1)\", filename):\n",
    "            m = re.search(f\"{start_key}_?(\\d+)\", filename)\n",
    "            if m:\n",
    "                starts.append(int(m.group(1)))\n",
    "\n",
    "    fuite_bool = re.search(r\"boolFuites_(\\d)_(\\d)_(\\d)_(\\d)\", filename) # Cas avec les fuites\n",
    "    fuite_start = re.search(r\"startFuites_(\\d+)_(\\d+)_(\\d+)_(\\d+)\", filename)\n",
    "    if fuite_bool and fuite_start:\n",
    "        bools = list(map(int, fuite_bool.groups()))\n",
    "        vals = list(map(int, fuite_start.groups()))\n",
    "        starts += [v for b, v in zip(bools, vals) if b == 1]\n",
    "\n",
    "    return min(starts) if starts else None\n",
    "\n",
    "\n",
    "def apply_rul(file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Charge un fichier CSV simulé et applique l’étiquetage RUL à partir du début du défaut.\n",
    "\n",
    "    - Charge le fichier CSV contenant les données capteurs d'une unité simulée.\n",
    "    - Détecte le début du défaut (via `extract_active_start`).\n",
    "    - Coupe le dataset à partir de ce moment.\n",
    "    - Calcule la RUL (Remaining Useful Life) comme la distance au temps final.\n",
    "    - Ne conserve que les colonnes standardisées (définies dans `common_cols`).\n",
    "    - Assigne un identifiant `unit_id` basé sur le nom de fichier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        Chemin vers un fichier CSV de simulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or None\n",
    "        Un dataframe avec les colonnes capteurs, la RUL, et l’`unit_id`,\n",
    "        ou None si le fichier ne contient pas de défaut exploitable.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture fichier {file} : {e}\")\n",
    "        return None\n",
    "\n",
    "    if \"Time\" not in df.columns:\n",
    "        print(f\"Colonne 'Time' absente dans {file}\")\n",
    "        return None\n",
    "\n",
    "    start = extract_active_start(os.path.basename(file))\n",
    "    if start is None:\n",
    "        print(f\"Aucun défaut actif détecté dans : {file}\")\n",
    "        return None\n",
    "\n",
    "    df = df[df[\"Time\"] >= start].copy()\n",
    "    end_time = df[\"Time\"].max()\n",
    "    df[\"RUL\"] = (end_time - df[\"Time\"]).round(2)  \n",
    "\n",
    "\n",
    "    df[\"unit_id\"] = os.path.basename(file)\n",
    "\n",
    "    missing_cols = [col for col in common_cols if col not in df.columns] # Ne garder que les colonnes communes\n",
    "    if missing_cols:\n",
    "        print(f\"[!] Fichier {file} ignoré (colonnes manquantes: {missing_cols})\")\n",
    "        return None\n",
    "\n",
    "    return df[common_cols + [\"RUL\", \"unit_id\"]]\n",
    "\n",
    "rul_dfs = []\n",
    "for sub in subfolders:\n",
    "    data_folder = os.path.join(base_folder, sub)\n",
    "    files = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "    print(f\"\\n[INFO] Traitement de {sub} ({len(files)} fichiers au total)\")\n",
    "\n",
    "    files_selected = []\n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        match = re.search(r\"Sim_(\\d+)_\", fname) # Cas \"classique\"\n",
    "        if not match:\n",
    "            match = re.search(r\"Sim_[a-zA-Z_]+_(\\d+)_\", fname) # Cas \"tuyaux\" → Sim_cc_t_xxx_ ou autre\n",
    "\n",
    "        if match:\n",
    "            sim_num = int(match.group(1))\n",
    "            if 1 <= sim_num <= 80:\n",
    "                files_selected.append(f)\n",
    "\n",
    "    print(f\"[INFO] → {len(files_selected)} fichiers sélectionnés pour {sub} (Sim 1 à 80)\")\n",
    "\n",
    "    for f in files_selected:\n",
    "        labeled = apply_rul(f)\n",
    "        if labeled is not None:\n",
    "            rul_dfs.append(labeled)\n",
    "\n",
    "if not rul_dfs:\n",
    "    print(\"\\n[NON] Aucun fichier exploitable dans tous les dossiers.\")\n",
    "else:\n",
    "    df_final = pd.concat(rul_dfs, ignore_index=True)\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    print(f\"\\n[OK] Export total vers : {output_file} ({df_final.shape[0]} lignes)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Etiquetage_RUL_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}